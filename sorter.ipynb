{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core Sample Reader\n",
    "## Sample project for Julia\n",
    "## Python 3.x, Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set our user-controllable variables\n",
    "\n",
    "**Important:** Your xlsx dataset will need to be properly formatted.  We use the \"Mockup\" sheet in data.xlsx for this example.  \n",
    "`source` should point to an xlsx with a single cell sample dataset.  _-quick note, the `r` before 'string' means that we treat it as a string-literal -- raw and unmodified_  \n",
    "`subject` should be the sheet name / sample subject in the source file\n",
    "`threshold` defines the threshold we use to identify the column we wish to mark  \n",
    "`cell_color` defines the highlight color in the resulting document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    source\n",
    "except:\n",
    "    source = r'L1 NM raw data.xlsx'\n",
    "try:\n",
    "    threshold\n",
    "except:\n",
    "    threshold = 100\n",
    "try:\n",
    "    cell_color\n",
    "except:\n",
    "    cell_color = r'#009933'\n",
    "try:\n",
    "    showoutput\n",
    "except:\n",
    "    showoutput = True\n",
    "try:\n",
    "    subject\n",
    "except:\n",
    "    subject = r'F74'\n",
    "try:\n",
    "    showcharts\n",
    "except:\n",
    "    showcharts = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Notebook Dependencies\n",
    "This tells python (specifically, the pip utility) to install a few dependencies that we're going to need.  `!` means \"this is a shell command, not a python statement\" in Jupyter, `{ }` interpolates the variable sys.executable into the statement.\n",
    "  \n",
    "-  numpy - swiss army tool for working with scientific data & numbers  \n",
    "-  pandas - tool to work with ordered, tabulated data.  Also allows us to directly read & write to xlsx formats  \n",
    "-  tabulate - allows us to pretty-print out our data in this example  \n",
    "-  openpyxl, xlsxwriter, xlrd - libraries for us to write to an excel (xlsx) document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (1.21.3)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (1.3.4)\n",
      "Requirement already satisfied: tabulate in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (0.8.9)\n",
      "Requirement already satisfied: openpyxl in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (3.0.9)\n",
      "Requirement already satisfied: xlsxwriter in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (3.0.1)\n",
      "Requirement already satisfied: xlrd in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (2.0.1)\n",
      "Requirement already satisfied: nbformat in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (5.1.3)\n",
      "Requirement already satisfied: Jinja2 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (3.0.2)\n",
      "Requirement already satisfied: plotly in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (5.3.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/julia/Library/Python/3.8/lib/python/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: et-xmlfile in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: traitlets>=4.1 in /Users/julia/Library/Python/3.8/lib/python/site-packages (from nbformat) (5.1.0)\n",
      "Requirement already satisfied: jupyter-core in /Users/julia/Library/Python/3.8/lib/python/site-packages (from nbformat) (4.8.1)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from nbformat) (4.1.2)\n",
      "Requirement already satisfied: ipython-genutils in /Users/julia/Library/Python/3.8/lib/python/site-packages (from nbformat) (0.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from Jinja2) (2.0.1)\n",
      "Requirement already satisfied: six in /Users/julia/Library/Python/3.8/lib/python/site-packages (from plotly) (1.16.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from plotly) (8.0.1)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat) (0.18.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat) (21.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 21.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import sys\n",
    "if showoutput:\n",
    "    !{sys.executable} -m pip install numpy pandas tabulate openpyxl xlsxwriter xlrd nbformat Jinja2 plotly\n",
    "else:\n",
    "    !{sys.executable} -m pip install numpy pandas tabulate openpyxl xlsxwriter xlrd nbformat Jinja2 plotly > /dev/null\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we `import` the libraries we want to use with import statements.  This effectively makes anything in their namespaces available in our application.  In this case, we'll use the optional `as` statement to alias the pandas & numpy libraries, and `from` to import the tabulate & display module inside their respective packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Onto the code!\n",
    "We use the Pandas library, which we've aliased to the `pd` namespace, to load the file contained in the variable `source`\n",
    "\n",
    "Pandas is a handy utility for manipulating excel-style data.  We set the `Region` & `Channel` index here for the initial grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'L1 NM raw data.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/r1/vsxc1hqx2jg6hlvjncz79rf80000gn/T/ipykernel_36462/3589905111.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msheet_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Region'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Channel'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         raise ValueError(\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1189\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1192\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m                 )\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1068\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1070\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m   1071\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m     ) as handle:\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 711\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    712\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'L1 NM raw data.xlsx'"
     ]
    }
   ],
   "source": [
    "data = pd.read_excel(source, sheet_name=subject).set_index(['Region','Channel'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's take a quick look at our data...\n",
    "We've reformatted our data to be a little simpler to use with Pandas.  We could load the existing data as-is with some slight modifications, and duplicate keys will show up as `key key.1 key.2 ...`, etc  \n",
    "This would require us to melt the table, pivot, & group - I think a better approach if possible is to restructure the data slightly as seen in the \"Mockup\" sheet.  I can help you write a data converter for all of your existing samples if you'd like, but the code will be a little difficult to follow.  \n",
    "\n",
    "So, for now you can see we've added Sample & Core columns and dropped it into a uniform array we can easily use in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if showoutput:\n",
    "    display(data)\n",
    "    print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yay! We have our data.  Now, we don't actually *need* to sort our data to identify the first core.max Δ > threshold, but we'll do it anyway to simplify the code even more.  There are multiple approaches here using aggregates, but the simplest is to just sort the lot using our indexes & regroup it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sorted_data = data.sort_values(by=['Region','Channel','Max'])\n",
    "if showoutput:\n",
    "    display(sorted_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, table is sorted by Max, now we can group the regions & channels for our Max Δ calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sorted_data['Max_Delta'] = sorted_data.groupby(['Region','Channel'])['Max'].diff()\n",
    "if showoutput:\n",
    "    display(sorted_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done! Now we just need to highlight our target data and write it out to an xlsx "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we generate a threshold table, using our calculated Max_Delta column.  We group on our indexes, and invoke first() on each group.  \n",
    "There are many approaches in selecting a first value, but Python & Pandas doesn't give us an elegant solution out of the box, and this is the easiest approach.  \n",
    "Additionally, we add the column `Max_Delta_First_Hit` to the `first_threshold_table` dataframe that we'll need later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "first_threshold_table = sorted_data.query('Max_Delta >= 100').groupby(['Region','Channel']).first()\n",
    "first_threshold_table['Max_Delta_First_Hit'] = True\n",
    "if showoutput:\n",
    "    display(first_threshold_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to merge the `first_threshold_table` dataframe with our `sorted_data` dataframe.  Calling .merge() will drop the indexes, so we first invoke reset_index() first  \n",
    "Our merge strategy in this scenario will be `left` - I'd recommend reading up on SQL & structured data `JOIN` operations to understand the methodology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = sorted_data.reset_index().merge(first_threshold_table, how='left')\n",
    "if showoutput:\n",
    "    display(merged_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a styler function to color our cells...  \n",
    "This bit is a little more complicated and convoluted due to how Pandas works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def style_when_true(series):\n",
    "    match_table = [1 if x == True else 0 for x in series]\n",
    "    return [f'background-color: {cell_color}' if v else '' for v in match_table]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to apply our formatter to highlight the cell using `Max_Delta_First_Hit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "formatted_data = merged_data.style.apply(style_when_true, subset='Max_Delta_First_Hit')\n",
    "if showoutput:\n",
    "        display(merged_data.head(25).style.apply(style_when_true, subset='Max_Delta_First_Hit'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time for part 2 - let's massage our data a little bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a new channel-based dataframe\n",
    "df_channel = pd.DataFrame(columns=[\n",
    "    'Region',\n",
    "    'Channel',\n",
    "    'Positive',\n",
    "    'Negative',\n",
    "    'Count',\n",
    "    'Positive_Ratio',\n",
    "])\n",
    "\n",
    "#Define a new region-based dataframe\n",
    "df_region = pd.DataFrame(columns=[\n",
    "    'Region',\n",
    "    'Count',\n",
    "    'C1_Positive',\n",
    "    'C1_Positive_Ratio',\n",
    "    'C2_Positive',\n",
    "    'C2_Positive_Ratio',\n",
    "    'C3_Positive',\n",
    "    'C3_Positive_Ratio',\n",
    "    'C1C2_Positive',\n",
    "    'C1C2_Positive_Ratio',\n",
    "    'C1C3_Positive',\n",
    "    'C1C3_Positive_Ratio',\n",
    "    'C2C3_Positive',\n",
    "    'C2C3_Positive_Ratio',\n",
    "    'C1C2C3_Positive',\n",
    "    'C1C2C3_Positive_Ratio',\n",
    "    'C1-Only_Positive',\n",
    "    'C1-Only_Positive_Ratio',\n",
    "    'C2-Only_Positive',\n",
    "    'C2-Only_Positive_Ratio',\n",
    "    'C3-Only_Positive',\n",
    "    'C3-Only_Positive_Ratio',\n",
    "    'C1C2-Only_Positive',\n",
    "    'C1C2-Only_Positive_Ratio',\n",
    "    'C1C3-Only_Positive',\n",
    "    'C1C3-Only_Positive_Ratio',\n",
    "    'C2C3-Only_Positive',\n",
    "    'C2C3-Only_Positive_Ratio',\n",
    "    'Negative',\n",
    "    'Negative_Ratio',\n",
    "])\n",
    "\n",
    "#Calculate our channel data, where a positive result is derived from Max > 0\n",
    "for i in merged_data.groupby(['Region','Channel']):\n",
    "    df_channel = df_channel.append({\n",
    "        'Region':i[0][0],\n",
    "        'Channel':i[0][1],\n",
    "        'Positive':sum(i[1]['Max'] > 0),\n",
    "        'Negative':sum(i[1]['Max'] <= 0),\n",
    "        'Count':len(i[1]),\n",
    "        'Positive_Ratio':sum(i[1]['Max'] > 0) / len(i[1]['Max'])\n",
    "        }, ignore_index=True)\n",
    "\n",
    "#Set indexer on channel dataframe\n",
    "df_channel = df_channel.set_index('Region')\n",
    "\n",
    "#Fill region dataframe with regions & zero out all values\n",
    "df_region.Region  = merged_data.Region.unique()\n",
    "df_region = df_region.set_index('Region')\n",
    "for col in df_region.columns:\n",
    "    df_region[col].values[:] = 0\n",
    "\n",
    "#Calculate our region data, where a positive result is derived from Max > 0 with 'AND' channel groupings\n",
    "for i in merged_data.groupby(['Region','ROI']):\n",
    "    try:\n",
    "        df_region.at[i[1].iloc[0]['Region'], 'Count'] += 1\n",
    "        df_region.at[i[1].iloc[0]['Region'], 'C1_Positive'] += i[1].iloc[0]['Max'] > 0\n",
    "        df_region.at[i[1].iloc[1]['Region'], 'C2_Positive'] += i[1].iloc[1]['Max'] > 0\n",
    "        df_region.at[i[1].iloc[2]['Region'], 'C3_Positive'] += i[1].iloc[2]['Max'] > 0\n",
    "        df_region.at[i[1].iloc[2]['Region'], 'C1C2_Positive'] += (i[1].iloc[0]['Max'] > 0) and (i[1].iloc[1]['Max'] > 0)\n",
    "        df_region.at[i[1].iloc[2]['Region'], 'C1C3_Positive'] += (i[1].iloc[0]['Max'] > 0) and (i[1].iloc[2]['Max'] > 0)\n",
    "        df_region.at[i[1].iloc[2]['Region'], 'C2C3_Positive'] += (i[1].iloc[1]['Max'] > 0) and (i[1].iloc[2]['Max'] > 0)\n",
    "        df_region.at[i[1].iloc[0]['Region'], 'C1-Only_Positive'] += i[1].iloc[0]['Max'] > 0 and (i[1].iloc[1]['Max'] <= 0) and (i[1].iloc[2]['Max'] <= 0)\n",
    "        df_region.at[i[1].iloc[1]['Region'], 'C2-Only_Positive'] += i[1].iloc[1]['Max'] > 0 and (i[1].iloc[0]['Max'] <= 0) and (i[1].iloc[2]['Max'] <= 0)\n",
    "        df_region.at[i[1].iloc[2]['Region'], 'C3-Only_Positive'] += i[1].iloc[2]['Max'] > 0 and (i[1].iloc[0]['Max'] <= 0) and (i[1].iloc[1]['Max'] <= 0)\n",
    "        df_region.at[i[1].iloc[2]['Region'], 'C1C2-Only_Positive'] += (i[1].iloc[0]['Max'] > 0) and (i[1].iloc[1]['Max'] > 0) and (i[1].iloc[2]['Max'] <= 0)\n",
    "        df_region.at[i[1].iloc[2]['Region'], 'C1C3-Only_Positive'] += (i[1].iloc[0]['Max'] > 0) and (i[1].iloc[2]['Max'] > 0) and (i[1].iloc[1]['Max'] <= 0)\n",
    "        df_region.at[i[1].iloc[2]['Region'], 'C2C3-Only_Positive'] += (i[1].iloc[1]['Max'] > 0) and (i[1].iloc[2]['Max'] > 0) and (i[1].iloc[0]['Max'] <= 0)\n",
    "        df_region.at[i[1].iloc[2]['Region'], 'C1C2C3_Positive'] += (i[1].iloc[0]['Max'] > 0) and (i[1].iloc[1]['Max'] > 0) and (i[1].iloc[2]['Max'] > 0)\n",
    "        df_region.at[i[1].iloc[2]['Region'], 'Negative'] += (i[1].iloc[0]['Max'] <= 0) and (i[1].iloc[1]['Max'] <= 0) and (i[1].iloc[2]['Max'] <= 0)\n",
    "    except Exception as e:\n",
    "        print(\"Data input issue, we ran into a problem here:\")\n",
    "        print(i)\n",
    "        raise(e)\n",
    "\n",
    "#Calculate ratios\n",
    "df_region['C1_Positive_Ratio'] = (df_region['C1_Positive'] / df_region['Count']).astype(np.double).round(5)\n",
    "df_region['C2_Positive_Ratio'] = (df_region['C2_Positive'] / df_region['Count']).astype(np.double).round(5)\n",
    "df_region['C3_Positive_Ratio'] = (df_region['C3_Positive'] / df_region['Count']).astype(np.double).round(5)\n",
    "df_region['C1C2_Positive_Ratio'] = (df_region['C1C2_Positive'] / df_region['Count']).astype(np.double).round(5)\n",
    "df_region['C1C3_Positive_Ratio'] = (df_region['C1C3_Positive'] / df_region['Count']).astype(np.double).round(5)\n",
    "df_region['C2C3_Positive_Ratio'] = (df_region['C2C3_Positive'] / df_region['Count']).astype(np.double).round(5)\n",
    "df_region['C1-Only_Positive_Ratio'] = (df_region['C1-Only_Positive'] / df_region['Count']).astype(np.double).round(5)\n",
    "df_region['C2-Only_Positive_Ratio'] = (df_region['C2-Only_Positive'] / df_region['Count']).astype(np.double).round(5)\n",
    "df_region['C3-Only_Positive_Ratio'] = (df_region['C3-Only_Positive'] / df_region['Count']).astype(np.double).round(5)\n",
    "df_region['C1C2-Only_Positive_Ratio'] = (df_region['C1C2-Only_Positive'] / df_region['Count']).astype(np.double).round(5)\n",
    "df_region['C1C3-Only_Positive_Ratio'] = (df_region['C1C3-Only_Positive'] / df_region['Count']).astype(np.double).round(5)\n",
    "df_region['C2C3-Only_Positive_Ratio'] = (df_region['C2C3-Only_Positive'] / df_region['Count']).astype(np.double).round(5)\n",
    "df_region['C1C2C3_Positive_Ratio'] = (df_region['C1C2C3_Positive'] / df_region['Count']).astype(np.double).round(5)\n",
    "df_region['Negative_Ratio'] = (df_region['Negative'] / df_region['Count']).astype(np.double).round(5)\n",
    "if showoutput:\n",
    "    display(df_region)\n",
    "    display(df_channel.groupby(['Region','Channel']).first())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just about done! All we need to do now is write out our dataframes to a new xlsx document.  We manually set our column sizes to keep things simple & readable.\n",
    "We currently write out a summary sheet containing the selected cells which exceeded the threshold in the dataset, and the data with highlighted styling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(f\"{subject}.xlsx\", engine='xlsxwriter') as writer:\n",
    "    first_threshold_table.to_excel(writer, sheet_name=f'{subject}-summary')\n",
    "    df_region.to_excel(writer, sheet_name=f'{subject}-regions')\n",
    "    df_channel.to_excel(writer, sheet_name=f'{subject}-channels')\n",
    "    formatted_data.to_excel(writer, sheet_name=subject, index=True)\n",
    "    \n",
    "    #Set column formats\n",
    "    workbook = writer.book\n",
    "    region_worksheet = writer.sheets[f'{subject}-regions']\n",
    "    pct_format = workbook.add_format({'num_format': '0.00%'})\n",
    "    region_worksheet.set_column('D:D', None, pct_format)\n",
    "    region_worksheet.set_column('F:F', None, pct_format)\n",
    "    region_worksheet.set_column('H:H', None, pct_format)\n",
    "    region_worksheet.set_column('J:J', None, pct_format)\n",
    "    region_worksheet.set_column('L:L', None, pct_format)\n",
    "    region_worksheet.set_column('N:N', None, pct_format)\n",
    "    region_worksheet.set_column('P:P', None, pct_format)\n",
    "    region_worksheet.set_column('R:R', None, pct_format)\n",
    "    region_worksheet.set_column('T:T', None, pct_format)\n",
    "    region_worksheet.set_column('V:V', None, pct_format)\n",
    "    region_worksheet.set_column('X:X', None, pct_format)\n",
    "    region_worksheet.set_column('Z:Z', None, pct_format)\n",
    "    region_worksheet.set_column('AB:AB', None, pct_format)\n",
    "    region_worksheet.set_column('AD:AD', None, pct_format)\n",
    "    \n",
    "    #Autofit columns\n",
    "    for sheetname, df in writer.sheets.items():\n",
    "        worksheet = writer.sheets[sheetname]\n",
    "        worksheet.set_column(0, 29, 25)\n",
    "print(f\"Successfully wrote {subject}.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congrats! We're done, and you should now have a new xlsx file based on the subject name.\n",
    "If this is the first time you've run the notebook, you should see a \"Mockup.xlsx\" file that you can right click and download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "Graphing your data is easy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install the plotly & jupyter widgets packages\n",
    "if showoutput:\n",
    "    !{sys.executable} -m pip install plotly ipywidgets\n",
    "else:\n",
    "    !{sys.executable} -m pip install plotly ipywidgets > /dev/null\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw an example chart using our original dataframe object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if showcharts:\n",
    "    for key in data.groupby(['Region','Channel']).groups.keys():\n",
    "        df = data.groupby(['Region','Channel']).get_group(key).reset_index().set_index('ROI')\n",
    "        fig = px.line(df, x=df.index, y=['Mean','Min','Area'], title=' - '.join(key))\n",
    "        fig.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "082e9a3bcad0a290d0001e938aa60b99250c6c2ef33a923c00b70f9826caf4b7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
